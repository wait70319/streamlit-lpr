import streamlit as st
import cv2
import numpy as np
import easyocr
from PIL import Image
import re

st.set_page_config(page_title="è»Šç‰Œè¾¨è­˜èˆ‡ç‰¹å¯«è¼¸å‡º", page_icon="ğŸ“¸", layout="wide")

@st.cache_resource(show_spinner="ğŸ“¥ ç³»çµ±æ­£åœ¨å–šé†’ AI æ¨¡å‹ï¼Œè«‹è€å¿ƒç­‰å€™...")
def load_model():
    return easyocr.Reader(['en'], gpu=False)

reader = load_model()

# ç¶­æŒ 1280px è§£æåº¦ï¼Œç¢ºä¿åˆæˆå‡ºä¾†çš„åœ–ç‰‡å¤ æ¸…æ™°
def resize_image(image, max_width=1280):
    h, w = image.shape[:2]
    if w > max_width:
        ratio = max_width / w
        new_h = int(h * ratio)
        resized_img = cv2.resize(image, (max_width, new_h))
        return resized_img
    return image

st.title("ğŸ“¸ è»Šç‰Œç…§ç‰‡è‡ªå‹•è¾¨è­˜èˆ‡ç•«ä¸­ç•«ç‰¹å¯«")
st.write("ç²¾æº–è¾¨è­˜è»Šç‰Œï¼Œä¸¦è‡ªå‹•ç”Ÿæˆå¸¶æœ‰ã€Œç´…æ¡†èˆ‡å¼•å°ç·šã€çš„å°ˆæ¥­ç‰¹å¯«åˆæˆåœ–ã€‚")

uploaded_file = st.file_uploader("é¸æ“‡åœ–ç‰‡æª”æ¡ˆ...", type=["jpg", "jpeg", "png"])

if uploaded_file is not None:
    image = Image.open(uploaded_file)
    # ç¢ºä¿è½‰ç‚º RGB æ ¼å¼ (Streamlit é¡¯ç¤ºéœ€è¦ RGB)
    original_img = np.array(image.convert('RGB'))
    
    img_np = resize_image(original_img, max_width=1280)
    img_h, img_w, _ = img_np.shape
    
    # å»ºç«‹ä¸€å€‹ç•«å¸ƒ (è¤‡è£½åŸåœ–)ï¼Œæˆ‘å€‘å°‡åœ¨é€™å€‹ç•«å¸ƒä¸Šä½œç•«
    final_output_img = img_np.copy()
    
    with st.spinner('â³ AI æ­£åœ¨æ·±åº¦æƒæä¸¦ç¹ªè£½ç‰¹å¯«åœ–ï¼Œè«‹ç¨å€™...'):
        # ã€ç¬¬ä¸€éšæ®µã€‘ï¼šæ‰¾è»Šç‰Œä½ç½®
        gray_img = cv2.cvtColor(img_np, cv2.COLOR_RGB2GRAY)
        results = reader.readtext(gray_img, allowlist='ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789-')
        
    if not results:
        st.warning("âš ï¸ æ‰¾ä¸åˆ°ä»»ä½•ç¬¦åˆçš„è»Šç‰Œã€‚")
    else:
        valid_detections = []

        for (bbox, text, prob) in results:
            (tl, tr, br, bl) = bbox
            # å–å¾—è»Šç‰Œåº§æ¨™ (åŠ ä¸Š int ç¢ºä¿ç‚ºæ•´æ•¸)
            x1, y1 = int(tl[0]), int(tl[1])
            x2, y2 = int(br[0]), int(br[1])
            
            center_y = (y1 + y2) / 2
            
            # æ’é™¤æµ®æ°´å° (ä¸Šä¸‹é‚Šç·£éæ¿¾)
            if center_y > (img_h * 0.85) or center_y < (img_h * 0.10):
                continue
            
            # æ ¼å¼æª¢æŸ¥
            text = text.upper().strip('-')
            if not re.search(r'^[A-Z0-9]{2,4}-[A-Z0-9]{2,4}$', text):
                continue
            if prob < 0.2:
                continue

            # --- è£åˆ‡ä¹¾æ·¨çš„è»Šç‰Œ ---
            padding = 5
            crop_y1 = max(0, y1 - padding)
            crop_y2 = min(img_h, y2 + padding)
            crop_x1 = max(0, x1 - padding)
            crop_x2 = min(img_w, x2 + padding)
            
            clean_cropped_plate = img_np[crop_y1:crop_y2, crop_x1:crop_x2]

            # ==========================================
            # ã€ç¬¬äºŒéšæ®µã€‘ï¼šAI äºŒå€¼åŒ–å­—é«”ç˜¦èº« (ç¶­æŒæœ€é«˜æº–ç¢ºç‡)
            # ==========================================
            zoom_plate = cv2.resize(clean_cropped_plate, None, fx=3.0, fy=3.0, interpolation=cv2.INTER_CUBIC)
            zoom_gray = cv2.cvtColor(zoom_plate, cv2.COLOR_RGB2GRAY)
            _, binary_plate = cv2.threshold(zoom_gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
            kernel = np.ones((3, 3), np.uint8)
            thinned_plate = cv2.dilate(binary_plate, kernel, iterations=1)
            final_feed = cv2.cvtColor(thinned_plate, cv2.COLOR_GRAY2RGB)
            
            final_text_result = reader.readtext(final_feed, detail=0, allowlist='ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789-')
            final_text = final_text_result[0] if len(final_text_result) > 0 else text

            valid_detections.append(final_text)

            # ==========================================
            # ã€ç¬¬ä¸‰éšæ®µã€‘ï¼šç¹ªè£½ç•«ä¸­ç•« (Picture-in-Picture) è¦–è¦ºç‰¹æ•ˆ
            # ==========================================
            
            # 1. æ±ºå®šæ”¾å¤§åœ–çš„å°ºå¯¸èˆ‡ä½ç½®
            # å°‡è£åˆ‡ä¸‹ä¾†çš„è»Šç‰Œæ”¾å¤§ 4 å€ä½œç‚ºé¡¯ç¤ºç”¨
            display_scale = 4.0
            pip_w = int((crop_x2 - crop_x1) * display_scale)
            pip_h = int((crop_y2 - crop_y1) * display_scale)
            pip_img = cv2.resize(clean_cropped_plate, (pip_w, pip_h), interpolation=cv2.INTER_CUBIC)
            
            # è¨­å®šç•«ä¸­ç•«æ”¾åœ¨å·¦ä¸Šè§’ (ç•™ 30px çš„é‚Šè·)
            pip_x1, pip_y1 = 30, 30
            pip_x2, pip_y2 = pip_x1 + pip_w, pip_y1 + pip_h
            
            # 2. å°‡æ”¾å¤§åœ–è²¼åˆ°ä¸»ç•«å¸ƒä¸Š
            final_output_img[pip_y1:pip_y2, pip_x1:pip_x2] = pip_img
            
            # 3. å®šç¾©ç´…è‰² (RGB æ ¼å¼ç‚º 255, 0, 0) èˆ‡ç·šæ¢ç²—ç´°
            RED = (255, 0, 0)
            THICKNESS = 4
            
            # 4. ç•«æ¡†èˆ‡é€£æ¥ç·š
            # ç•«å°è»Šç‰Œçš„ç´…æ¡†
            cv2.rectangle(final_output_img, (x1, y1), (x2, y2), RED, THICKNESS)
            # ç•«å·¦ä¸Šè§’æ”¾å¤§åœ–çš„ç´…æ¡†
            cv2.rectangle(final_output_img, (pip_x1, pip_y1), (pip_x2, pip_y2), RED, THICKNESS)
            
            # ç•«å¼•å°é€£æ¥ç·š (å¾æ”¾å¤§åœ–çš„å³ä¸‹è§’ï¼Œé€£åˆ°åŸè»Šç‰Œçš„å·¦ä¸Šè§’)
            pt_pip_bottom_right = (pip_x2, pip_y2)
            pt_plate_top_left = (x1, y1)
            cv2.line(final_output_img, pt_pip_bottom_right, pt_plate_top_left, RED, THICKNESS)

        # --- å–®ä¸€ç•«é¢è¼¸å‡º ---
        if len(valid_detections) == 0:
            st.info("æ²’æœ‰æ‰¾åˆ°ç¬¦åˆæ¨™æº–çš„è»Šç‰Œã€‚")
        else:
            # é¡¯ç¤ºé€™å¼µå……æ»¿ç§‘æŠ€æ„Ÿçš„åˆæˆå¤§åœ–
            st.image(final_output_img, use_column_width=True, caption="è‡ªå‹•ç‰¹å¯«åˆæˆåœ–")
            
            # åœ¨åœ–ç‰‡ä¸‹æ–¹ç”¨é†’ç›®çš„å­—é«”åˆ—å‡ºè¾¨è­˜çµæœ
            for text in valid_detections:
                st.success(f"ğŸ¯ **AI æœ€çµ‚è¾¨è­˜çµæœï¼š {text}**")
